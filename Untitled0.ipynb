{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''%pip install google-colab-selenium[undetected]\n",
        "%pip install requests_html\n",
        "%pip install lxml_html_clean\n",
        "!pyppeteer-install\n",
        "'''\n",
        "%pip install rdkit"
      ],
      "metadata": {
        "id": "luvaX6r7MPt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ОСНОВНОЙ КОД**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "iBEiY9ZuvkVB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "enJw3C4QtmYU"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "#from selenium import webdriver\n",
        "import csv\n",
        "import time\n",
        "import urllib.parse\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "from rdkit import Chem\n",
        "\n",
        " # Параметры для скачки датасета с сайта\n",
        "baseurl = \"https://www.ebi.ac.uk/chembl/interface_api/delayed_jobs/outputs/DOWNLOAD-H2BOukkSKkmhZbkSsqEHUFI7OXmvQPQGZ89SSqj1CTk_eq_/DOWNLOAD-H2BOukkSKkmhZbkSsqEHUFI7OXmvQPQGZ89SSqj1CTk_eq_.zip\"\n",
        "data_file_path = '/content/DOWNLOAD-H2BOukkSKkmhZbkSsqEHUFI7OXmvQPQGZ89SSqj1CTk_eq_.zip'\n",
        "archive = 'DOWNLOAD-H2BOukkSKkmhZbkSsqEHUFI7OXmvQPQGZ89SSqj1CTk_eq_.zip'\n",
        "\n",
        " # Фукнция скачивающая и открывающая файл\n",
        "def webparser(baseurl):\n",
        "  destination = 'DOWNLOAD-H2BOukkSKkmhZbkSsqEHUFI7OXmvQPQGZ89SSqj1CTk_eq_.zip'\n",
        "  url = baseurl\n",
        "  urllib.request.urlretrieve(url, destination)\n",
        "   # скачали\n",
        "\n",
        "  archive = 'DOWNLOAD-H2BOukkSKkmhZbkSsqEHUFI7OXmvQPQGZ89SSqj1CTk_eq_.zip'\n",
        "  with zipfile.ZipFile(archive, 'r') as zip_file:\n",
        "      zip_file.extractall('/content')\n",
        "   # разархивировали\n",
        "\n",
        " # Парсер по CSV файлу\n",
        "def dataparser(data_file_path):\n",
        "  dforig = pd.read_csv(data_file_path, sep=';')\n",
        "\n",
        "   # Печатаем все названия колонок чтобы выбросить ненужные\n",
        "   # print(dforig.columns.values)\n",
        "  exccolumns = list(set([i for i in range (0, 48)]) - set([0, 3, 7, 8, 9, 10, 11]))\n",
        "   # print(exccolumns)\n",
        "\n",
        "\n",
        "   # Функция удаления плохих значений\n",
        "  def drop_stoopid():\n",
        "\n",
        "     # Удаляем ненужные колонки\n",
        "    df = dforig.drop(dforig.columns[exccolumns], axis=1)\n",
        "    #print(df['Standard Units'].unique())\n",
        "\n",
        "     # Удаляем все значение НЕ IC50\n",
        "    index = df[df['Standard Type'] != \"IC50\"].index\n",
        "    #print(index)\n",
        "    df = df.drop(index)\n",
        "     # print(df)\n",
        "\n",
        "     # Удаляем пустые ячейки во всех колонках\n",
        "    df = df.dropna(subset=['Standard Value', 'Smiles', 'Molecule ChEMBL ID', 'Molecular Weight', ])\n",
        "     # print(df)\n",
        "\n",
        "     # Удаляем дупликаты ID молекул\n",
        "    df = df.drop_duplicates(subset=[\"Molecule ChEMBL ID\"])\n",
        "     # print(df)\n",
        "\n",
        "     # Удаляем ячейки где не сходятся IC50 и Standard Value, а также вспомогательный Standard Relation ибо он больше не нужен\n",
        "    index = df[df['Standard Relation'] != \"'='\"].index\n",
        "    #print(index)\n",
        "    print(df)\n",
        "    df = df.drop(index)\n",
        "    df = df.drop('Standard Relation', axis=1)\n",
        "    print(df)\n",
        "     # print(df['Standard Units'].unique())\n",
        "\n",
        "\n",
        "     # Функция проверки SMILES и Units\n",
        "    def checker():\n",
        "\n",
        "       # Проверяем каждую строчку SMILES на адекватность\n",
        "      dfs=df\n",
        "      for entry in dfs['Smiles']:\n",
        "        #print(entry)\n",
        "        #print(entry)\n",
        "        #print(Chem.MolFromSmiles(entry))\n",
        "        mol = Chem.MolFromSmiles(entry)\n",
        "        if mol == None:\n",
        "          dfs.drop(entry)\n",
        "        try:\n",
        "          Chem.SanitizeMol(mol)\n",
        "        except Exception:\n",
        "          dfs.drop(entry)\n",
        "\n",
        "       # Удаляем строчки в которых значения не в наноМолях, их всего 15\n",
        "      index = dfs[dfs['Standard Units'] != \"nM\"].index\n",
        "      #print(index)\n",
        "      dfs = dfs.drop(index)\n",
        "      #for index, row in dfs.iterrows():\n",
        "        #if row['Standard Units'] == '%' or row['Standard Units'] == 'ug':\n",
        "          #dfs.drop(index)\n",
        "        #print(row['Standard Value'], row['Standard Units'])\n",
        "      #print(dfs)\n",
        "      #print(dfs)\n",
        "      return dfs\n",
        "    dfs = checker()\n",
        "    return dfs\n",
        "  dfs = drop_stoopid()\n",
        "  return dfs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "webparser(baseurl)"
      ],
      "metadata": {
        "id": "FC3IzTwzMqq-"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataparser(data_file_path)\n",
        "\n",
        " # записываем в CSV файл 3 полезные нам колонки 'Molecule ChEMBL ID', 'Smiles', 'Standard Value'\n",
        "with open('Parsed_data.csv', 'w', newline='', encoding='utf-8'):\n",
        "    data.to_csv('Parsed_data.csv', columns = ['Molecule ChEMBL ID', 'Smiles', 'Standard Value'], index = False)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5oMsK0ot8DEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10 ТЫСЯЧ НЕРАБОЧИХ ПАРСЕРОВ**"
      ],
      "metadata": {
        "id": "wGRqgrbczz-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "from requests_html import HTMLSession\n",
        "\n",
        "session = HTMLSession()\n",
        "r = session.get('https://www.ebi.ac.uk/chembl/explore/activities/STATE_ID:A7tQ9Eh8n8uuiWNfvBq-yw%3D%3D')\n",
        "r.html.render()  # выполняет JavaScript\n",
        "print(r.html.html)\n",
        "'''\n",
        "\n",
        "'''\n",
        "from requests_html import AsyncHTMLSession\n",
        "import asyncio\n",
        "\n",
        "async def scrape_chembl():\n",
        "    asession = AsyncHTMLSession()\n",
        "    r = await asession.get('https://www.ebi.ac.uk/chembl/explore/activities/STATE_ID:A7tQ9Eh8n8uuiWNfvBq-yw%3D%3D')\n",
        "    await r.html.arender()  # Note the 'a' prefix for async methods\n",
        "    print(r.html.html)\n",
        "    await asession.close()\n",
        "\n",
        "# Run in Colab\n",
        "await scrape_chembl()\n",
        "\n",
        "baseurl = \"https://www.ebi.ac.uk/chembl/explore/activities/STATE_ID:A7tQ9Eh8n8uuiWNfvBq-yw%3D%3D\"\n",
        "'''\n",
        "'''def myparser(EnzymeID):\n",
        "  baseurl = \"https://www.ebi.ac.uk/chembl/explore/activities/STATE_ID:A7tQ9Eh8n8uuiWNfvBq-yw%3D%3D\"\n",
        "  response = urllib.request.urlopen(baseurl)\n",
        "\n",
        "  headers = {\"useragent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36\"\n",
        "  }\n",
        "  response = requests.get(baseurl, headers)\n",
        "  print(response.status_code)\n",
        "  print(response.ok)\n",
        "\n",
        "  f = urllib.request.urlopen(response)\n",
        "  print(f)\n",
        "  print('CHEMBL305660' in data)\n",
        "  '''\n",
        "'''def myparser(EnzymeID):\n",
        "  baseurl = \"https://www.ebi.ac.uk/chembl/explore/activities/STATE_ID:A7tQ9Eh8n8uuiWNfvBq-yw%3D%3D\"\n",
        "  response = urllib.request.urlopen(baseurl)'''\n"
      ],
      "metadata": {
        "id": "LtCHyBIXNZ8l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}